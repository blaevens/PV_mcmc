{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "1. [Introduction](#part1)\n",
    "2. [Settings](#part2)\n",
    "3. [Synthetic data](#part3)\n",
    "4. [Processing data](#part4)\n",
    "5. [Markov Chain Monte Carlo](#part5)\n",
    "6. [Visualisation Results](#part6)   \n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction <a class=\"anchor\" id=\"part1\"></a>\n",
    "This notebook is an accompaniment to a research project entitled *A Markov Chain Monte Carlo approach for the estimation of photovoltaic system parameters*. In this project, we have devised a method to determine the orientation ($\\phi$), tilt ($\\theta$) and number of panels ($N_{p}$) or system size of photovoltaic (PV) systems using a Markov Chain Monte Carlo (MCMC) approach. We identify clear day observed profiles from the online portal PVOutput (www.pvoutput.org) and compare these to modelled profiles from the PVLib library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Settings <a class=\"anchor\" id=\"part2\"></a>\n",
    "\n",
    "It is highly recommended that you create an environment which will allow this notebook to run smoothly. This project has been tested in Linux using Python 3.7, where pyenv was used for the Python version mangement and virtualenv was used to create the environment. Please see the requirements.txt file demonstrating which packages are necessary. It may be necessary to add the Python environment kernel to the Jupyter notebook before being able to run the code in the notebook. This can be done with something like: python -m ipykernel install --name pv_mcmc. Also, don't forget to first activate the environment before running the Jupyter-notebook. This can be achieved by doing something along the following lines:\n",
    "source ./.venv/bin/activate\n",
    "\n",
    "This project has not yet been tested in any other operating system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import standard Python functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pvlib\n",
    "import emcee\n",
    "import os, sys\n",
    "from IPython.display import Image\n",
    "sys.path.append('./scripts')\n",
    "# Import custom functions\n",
    "import mcmc_functions_4D as mcmc\n",
    "import data_processing_4D as processing\n",
    "import synthetic_data_4D as synthetic\n",
    "import plot_functions_4D as plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set and create directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "home_path = os.path.realpath('.')\n",
    "os.path.isdir('new_folder')\n",
    "data_path = os.path.join(home_path, 'mock_data/')\n",
    "chains_path = os.path.join(home_path, 'mcmc_chains/')\n",
    "plots_path = os.path.join(home_path, 'mcmc_plots/')\n",
    "\n",
    "# Create directories if they do not already exist\n",
    "paths = [data_path, chains_path, plots_path]\n",
    "processing.create_directories(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Synthetic or observed data <a class=\"anchor\" id=\"part3\"></a>\n",
    "While in the original research paper, we used PVOutput data to determine PV system parameters we cannot provide these in this repository. For those interested in the original data, we refer the reader to the following Github page, which is a dedicated library for downloading PVOutput data: https://github.com/openclimatefix/pvoutput. We also provide code to read in the pvoutput data (in the format we received the data). To allow us to demonstrate our technique, we generate some synthetic data using PVLib, which we subsequently use as our observed data. The user is free to generate these data for different system specifications and/or days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define whether the notebook is run with synthethic or real pvoutput data. \n",
    "# This notebook will only run with the synthethic option unless you have your own copy of PVOutput data.\n",
    "option = 'synthetic'\n",
    "\n",
    "\n",
    "if (option == 'synthetic'):\n",
    "    # Define system IDs.\n",
    "    lst_ids = [1, 2, 3]\n",
    "\n",
    "    # Define the following 5 parameters: latitude, longitude, tilt, orientation and number of panels\n",
    "    sys1 = [52, 5, 20, 270, 8]\n",
    "    sys2 = [54, 7, 40, 50, 24]\n",
    "    sys3 = [53, 6, 60, 140, 16]\n",
    "    specs = [sys1, sys2, sys3]\n",
    "    meta = list(zip(lst_ids, specs))\n",
    "\n",
    "    # Define time resolution of profiles (in minutes).\n",
    "    time_resolution = '5'\n",
    "\n",
    "    # Define the clear sky days\n",
    "    lst_dates = ['20160508', '20170526', '20180505']\n",
    "\n",
    "    # Check if files already exist. If files already exist, you will be asked whether you wish to continue: Y/N.\n",
    "    #files_check = synthetic.check_files(meta, data_path)\n",
    "    files_check = 'Y'\n",
    "    # If yes or if the files do not exist yet: synthetic data will be created\n",
    "    if files_check=='Y':\n",
    "        synthetic.create_observations(meta, lst_dates, data_path, time_resolution)\n",
    "        synthetic.add_noise(lst_ids, lst_dates, data_path)\n",
    "else:\n",
    "    # define path where the pvoutput data is stored. Modify line below to suit your needs.\n",
    "    pvo_path = os.path.join(home_path, 'pvoutput_data/')\n",
    "    print('skipping synthethic data creation because you have chosen to run with real data.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data manipulation <a class=\"anchor\" id=\"part4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieve meta data (lon and lat) for system\n",
    "if (option == 'synthetic'):\n",
    "    # Select system and date for which to perform MCMC.\n",
    "    sid = 1\n",
    "    date = '20160508'; year = int(date[0:4]); month = int(date[4:6]); day = int(date[6:8])\n",
    "\n",
    "    # Define time resolution of profiles (in minutes). This need not be the same as the observed profiles.\n",
    "    time_resolution = '5'\n",
    "    lat, lon = processing.retrieve_meta(sid, data_path)\n",
    "    \n",
    "    # Obtain measurement data for system\n",
    "    dict_measurement = processing.retrieve_measurements(sid, date, data_path, option)\n",
    "    \n",
    "elif (option == 'real'):\n",
    "    # Select system and date for which to perform MCMC.\n",
    "    sid = 25918\n",
    "    date = '20180507'; year = int(date[0:4]); month = int(date[4:6]); day = int(date[6:8])\n",
    "    \n",
    "    # Define time resolution of profiles (in minutes). This need not be the same as the observed profiles.\n",
    "    time_resolution = '5'\n",
    "    lat, lon = processing.retrieve_meta(sid, pvo_path)\n",
    "    \n",
    "    # Obtain measurement data for system\n",
    "    dict_measurement = processing.retrieve_measurements(sid, date, pvo_path, option)\n",
    "\n",
    "\n",
    "\n",
    "# Define naive times\n",
    "times, ymd, hm, timezone = processing.get_naive_times(date, time_resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Markov Chain Monte Carlo <a class=\"anchor\" id=\"part5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine number of walkers and iterations for MCMC\n",
    "theta_var = 20; phi_var = 20; Np_var = 2; sigma_var = 1; ndim = 4; nwalkers = 40;\n",
    "variation = [theta_var, phi_var, Np_var, sigma_var]\n",
    "\n",
    "# Set guess values for theta, phi and Np, which are used for first iteration in MCMC\n",
    "#theta_guess, phi_guess, Np_guess, sigma_guess = mcmc.guess_values()\n",
    "theta_guess, phi_guess, Np_guess, sigma_guess = 20, 270, 8, 1\n",
    "guess_values = theta_guess, phi_guess, Np_guess, sigma_guess; guess_values = np.array(guess_values)\n",
    "\n",
    "# Determine the starting values for a Gaussian ball around the guess parameters\n",
    "guess_values = mcmc.get_starting_values_ball(guess_values, ndim, nwalkers, variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the parameters for which to run the burn in.\n",
    "minClusters = 1; maxClusters = 3;\n",
    "# CAUTION: Define the number of processors for which to run the MCMC. Here I have chosen 8, but check how many you have available to you.\n",
    "nproc = 8; \n",
    "sandia_modules = pvlib.pvsystem.retrieve_sam('SandiaMod')\n",
    "sapm_inverters = pvlib.pvsystem.retrieve_sam('cecinverter')\n",
    "iterations = 10000;\n",
    "\n",
    "system_meta = sid, lon, lat, timezone\n",
    "system_measurements = dict_measurement, times, hm\n",
    "mcmc_config = nwalkers, ndim, nproc, iterations, guess_values\n",
    "pvlib_databases = sandia_modules, sapm_inverters\n",
    "clustering_params = minClusters, maxClusters\n",
    "paths = chains_path, plots_path\n",
    "sampling_state = mcmc.burnin(system_meta, system_measurements, date, mcmc_config, pvlib_databases, \\\n",
    "                                        clustering_params, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# update the MCMC configuration for which to run the sampling, i.e. nwalkers and guess_values = sampling_state\n",
    "nwalkers = 8\n",
    "mcmc_config = nwalkers, ndim, nproc, iterations, sampling_state\n",
    "mcmc.sampling(system_meta, system_measurements, date, mcmc_config, pvlib_databases, \\\n",
    "                                      clustering_params, paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Visualisation Results <a class=\"anchor\" id=\"part5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat_samples = plot.retrieve_samples(sid, date, nwalkers, iterations, chains_path)\n",
    "\n",
    "# Obtain the best fit values + uncertainties for the parameters\n",
    "df_params, lst_params = plot.retrieve_best_params(flat_samples, ndim, 2)\n",
    "display(df_params)\n",
    "plot.plot_pdfs(flat_samples, sid, date, nwalkers, iterations, plots_path, lst_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compare observed and modelled profiles\n",
    "time_resolution = 5\n",
    "print(date)\n",
    "plot.observed_modelled_profiles(sid, date, time_resolution, data_path, df_params, option)\n",
    "\n",
    "# Probability Density Functions for the three different parameters\n",
    "display(Image(plots_path + 'pdfs_id%s_%s_w%s_i%s.png' %(str(sid), date, str(8), str(iterations)), width = 700, height = 700))\n",
    "\n",
    "# Auto correlation time\n",
    "display(Image(plots_path + 'autocorrelation_id%s_%s_w%s_i%s.png' %(str(sid), date, str(8), str(iterations))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
